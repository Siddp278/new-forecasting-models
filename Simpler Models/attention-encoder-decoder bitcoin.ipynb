{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://towardsdatascience.com/time-series-forecasting-with-deep-learning-and-attention-mechanism-2d001fc871fc"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13939,"status":"ok","timestamp":1689717251956,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"AphLIqNSsau6"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.preprocessing import MinMaxScaler\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import random\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1689717251957,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"HAxeW666sau8"},"outputs":[],"source":["# Setting hyperparameters\n","n_iters = 299969\n","epochs = 1\n","learning_rate = 0.001\n","batch_size = 128\n","lr_decay = False\n","hidden_size = 64\n","num_layers = 1\n","teacher_forcing_ratio = 0.5"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1689717252460,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"ejn02Xeosau8","outputId":"91ea0309-2ce7-4e36-f008-818a1514c975"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","\n","# path = 'drive/MyDrive/code/bitcoin_data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv'\n","path = \"bitcoin_data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12399,"status":"ok","timestamp":1689717264857,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"46rEEbIAsau9"},"outputs":[],"source":["df1 = pd.read_csv(path)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1689717265144,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"_8U4N9o1sau9","outputId":"166db223-1506-4903-f6bc-6dbfe2860077"},"outputs":[{"name":"stdout","output_type":"stream","text":["(4857377, 8)\n"]},{"data":{"text/plain":["Timestamp            0\n","Open                 0\n","High                 0\n","Low                  0\n","Close                0\n","Volume_(BTC)         0\n","Volume_(Currency)    0\n","Weighted_Price       0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df1['Volume_(BTC)'].fillna(value=0, inplace=True)\n","df1['Volume_(Currency)'].fillna(value=0, inplace=True)\n","df1['Weighted_Price'].fillna(value=0, inplace=True)\n","\n","# next we need to fix the OHLC (open high low close) data which is a continuous timeseries so\n","# lets fill forwards those values...\n","df1['Open'].fillna(method='ffill', inplace=True)\n","df1['High'].fillna(method='ffill', inplace=True)\n","df1['Low'].fillna(method='ffill', inplace=True)\n","df1['Close'].fillna(method='ffill', inplace=True)\n","\n","print(df1.shape)\n","df1.isnull().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689717265144,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"2d2c0QX4sau-"},"outputs":[],"source":["def generate_data(X, window, horizon=0):\n","  features = []\n","  y = []\n","  for i in range(0, len(X)-window-1-horizon):\n","    features.append(X[i:window+i])\n","    y.append(X[window+i: window+i+horizon])\n","  return np.array(features), np.array(y)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1689717265263,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"gY-B1SMUsau-"},"outputs":[],"source":["scaler = MinMaxScaler()\n","scaler.fit(df1[\"Weighted_Price\"].to_numpy().reshape(-1, 1))\n","data = scaler.transform(df1[\"Weighted_Price\"].to_numpy().reshape(-1, 1))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689717265263,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"KEjw8hdusau-"},"outputs":[],"source":["# Generating dataset\n","\n","class bitcoin(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","        self.len = X.shape[0]\n","\n","    def __len__(self):\n","        return self.len\n","\n","    def __getitem__(self, index):\n","        # print(index)\n","        # print(self.X[index])\n","        # print(self.y[index])\n","        return torch.Tensor(self.X[index]), torch.Tensor([self.y[index]]).squeeze()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":14896,"status":"ok","timestamp":1689717280158,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"Alwm5Q2Ksau-"},"outputs":[],"source":["window = 60\n","horizon = 4\n","\n","X, y = generate_data(data[2400000:4800000], window, horizon)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1689717280368,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"FxUw5ODVsau_","outputId":"745b177d-fbd5-4228-9472-3b11d48f5193"},"outputs":[{"data":{"text/plain":["((2399935, 60, 1), (2399935, 4, 1))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, y.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689717280369,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"C3IbjRC9sau_"},"outputs":[],"source":["train = bitcoin(X.squeeze()[:2299935], y.squeeze()[:2299935])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689717280369,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"W-BSqMtbsau_"},"outputs":[],"source":["val = bitcoin(X.squeeze()[2299935:2349935], y.squeeze()[2299935:2349935])"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689717280369,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"KeXe24fvsau_"},"outputs":[],"source":["test = bitcoin(X.squeeze()[2349935:2399934], y.squeeze()[2349935:2399934])"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1689717280370,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"z59NDNrIsau_"},"outputs":[],"source":["train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n","val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n","test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689717280451,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"pEKIIfOwsau_","outputId":"53861121-2452-47b7-f447-bfce5e902b8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 60]) torch.Size([128, 4])\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-8-27c25bd15a4a>:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  return torch.Tensor(self.X[index]), torch.Tensor([self.y[index]]).squeeze()\n"]}],"source":["dataset_iter = iter(train_loader)\n","temp = next(dataset_iter)\n","features, labels = temp\n","print(features.shape, labels.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":85,"status":"ok","timestamp":1689717280535,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"DQGo8onusau_"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, seq_len, input_shape, hidden_size, num_layers):\n","        super(Encoder, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden = hidden_size\n","        self.input_shape = input_shape\n","        self.gru = nn.GRU(input_shape, hidden_size, num_layers, batch_first=True)\n","\n","    def forward(self, input):\n","        # input [batch, window]\n","        # hidden = torch.zeros([self.num_layers, self.hidden]).cuda()\n","        # hidden = torch.zeros([self.num_layers, batch_size, self.hidden]).cuda()\n","        output, hidden = self.gru(input)\n","        return output, hidden"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689717280535,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"yQfqmD3KsavA"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, seq_len, input_shape, hidden_size, num_layers):\n","        super(Decoder, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden = hidden_size\n","        self.input_shape = input_shape\n","        self.gru = nn.GRU(input_shape + hidden_size, hidden_size, num_layers, batch_first=True)\n","\n","        # For computing attention\n","        self.w1 = nn.Linear(hidden_size, hidden_size)\n","        self.w2 = nn.Linear(hidden_size, hidden_size)\n","        self.w3 = nn.Linear(hidden_size, 1)\n","\n","        # Initialize fully connected layer\n","        self.final = nn.Linear(hidden_size, 1)\n","\n","    def compute_attention(self, dec_hs, enc_output):\n","        # dec_hs: Decoder hidden state; [1, batch_size, hidden_units]\n","        # enc_output: Encoder outputs; [batch_size, window, hidden_units]\n","        dec_x = dec_hs.permute(1, 0, 2)\n","\n","        # context_vector: Context vector, according to formula; [batch_size, hidden_units]\n","        # attention_weights: The attention weights you have calculated; [batch_size, max_len_src, 1]\n","\n","        # alignment scores e(j,t)\n","        out = torch.tanh(self.w1(dec_x) + self.w2(enc_output))\n","        out = self.w3(out)\n","\n","        # he scores e(j,t) are normalized using softmax function over the encoder time steps j, obaining the attention weights α(j,t)\n","        soft = nn.Softmax(dim=1)\n","        attention = soft(out)\n","\n","        #  The context vector c(t) is calculated as the weighted sum of all the hidden values of the encoder according to the attention weights\n","        # context vector [batch_size, hidden_units]\n","        # attention weights [batch_size, max_len_src, 1]\n","        context_vector, attention_weights = torch.sum(\n","            attention * enc_output, dim=1), attention\n","        return context_vector, attention_weights\n","\n","\n","    def forward(self, input, dec_hs, enc_output):\n","        # **This function runs the decoder for a single time step.**\n","        # input [batch_size, 1]\n","\n","        # hidden = torch.zeros([self.num_layers, self.hidden]).cuda()\n","        # hidden = torch.zeros([self.num_layers, batch_size, self.hidden]).cuda()\n","\n","        context_vector, attention_weights = self.compute_attention(dec_hs, enc_output)\n","        # context vector [batch, hidden_size]\n","        s = input.size(0)\n","        out = torch.cat((context_vector.unsqueeze(1), input.reshape(s, 1, 1)), 2)\n","        fc_out, dec_hs = self.gru(out)\n","        output = self.final(fc_out)\n","        final_out = torch.flatten(output, start_dim = 1)\n","\n","        return final_out, dec_hs, attention_weights"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1689717280535,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"Mp84FuRM1RwJ","outputId":"92cac872-ab1f-434b-f0f9-b62e5a606e00"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 60, 64]) torch.Size([1, 128, 64])\n"]}],"source":["# Test encoder model,\n","input_shape = 1\n","enc_test = Encoder(window, input_shape, hidden_size, num_layers=1).to(device)\n","# (seq,btch,in_sh)\n","out, h = enc_test(features.unsqueeze(2).to(device))\n","print(out.shape, h.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126,"status":"ok","timestamp":1689717280660,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"JhLyCNwXzLaU","outputId":"843489fa-dc97-48ae-d407-103c20467d8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 1]) torch.Size([1, 128, 64]) torch.Size([128, 60, 1])\n"]}],"source":["# Test decoder model,\n","input_shape = 1\n","dec_test = Decoder(window, input_shape, hidden_size, num_layers=1).to(device)\n","# (seq,btch,in_sh)\n","input = features[:, 0].to(device)\n","dec_hs = torch.zeros([num_layers, batch_size, hidden_size]).to(device)\n","out, dec_hs, att = dec_test(input, dec_hs, out)\n","print(out.shape, dec_hs.shape, att.shape)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1689720098520,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"LaK_9vCZAWiq"},"outputs":[],"source":["input_shape = 1\n","encoder = Encoder(window, input_shape, hidden_size, num_layers=1).to(device)\n","\n","decoder = Decoder(window, input_shape, hidden_size, num_layers=1).to(device)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":78,"status":"ok","timestamp":1689720099329,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"6Kr0gU6MAWt8"},"outputs":[],"source":["criterion = nn.MSELoss()\n","rnn_model_params = list(encoder.parameters()) + list(decoder.parameters())\n","optimizer = torch.optim.Adam(rnn_model_params, lr=learning_rate)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"executionInfo":{"elapsed":38938,"status":"error","timestamp":1689721260419,"user":{"displayName":"Siddharth Patra","userId":"17779542362729014501"},"user_tz":300},"id":"ZxYs7GIu2lfV","outputId":"c5325651-62a4-40aa-a9f1-33141e74f4cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration:100, Loss: [2.1276073312037624e-05]\n","Iteration:200, Loss: [2.579393367341254e-05]\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-eb6a132f9e2c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# run code below for every timestep in the ys batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0;31m# assert len(predictions.shape) == 2 and predictions.shape[0] == dec_input.shape[0] and predictions.shape[1] == len(trg_vocab.word2idx), \"First output of decoder must have shape [batch_size, vocab_size], you returned shape \" + str(predictions.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mmse_train_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-e618e4bc9b2a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, dec_hs, enc_output)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# hidden = torch.zeros([self.num_layers, batch_size, self.hidden]).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m# context vector [batch, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-e618e4bc9b2a>\u001b[0m in \u001b[0;36mcompute_attention\u001b[0;34m(self, dec_hs, enc_output)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# alignment scores e(j,t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(epochs):\n","  n_batch = 0\n","  total_loss = 0\n","\n","  for batch_x, batch_y in train_loader:\n","    n_batch += 1\n","    mse_train = 0\n","    batch_x = batch_x.to(device)\n","    batch_y = batch_y.to(device)\n","    batch_x = batch_x.unsqueeze(2)\n","    batch_y = batch_y.unsqueeze(2)\n","    optimizer.zero_grad()\n","\n","    enc_output, enc_hidden = encoder(batch_x)\n","    dec_hidden = enc_hidden\n","\n","    # use teacher forcing - feeding the target as the next input (via dec_input)\n","    dec_input = batch_y[:, 0].view(batch_size, 1, 1)\n","\n","    # run code below for every timestep in the ys batch\n","    for t in range(1, batch_y.size(1)):\n","      predictions, dec_hidden, _ = decoder(dec_input.to(device), dec_hidden.to(device), enc_output.to(device))\n","      # assert len(predictions.shape) == 2 and predictions.shape[0] == dec_input.shape[0] and predictions.shape[1] == len(trg_vocab.word2idx), \"First output of decoder must have shape [batch_size, vocab_size], you returned shape \" + str(predictions.shape)\n","      mse_train_step = criterion(batch_y[:, t], predictions)\n","      mse_train += mse_train_step\n","      dec_input = batch_y[:, t].view(batch_y.size(0), 1, 1)\n","\n","    batch_loss = mse_train / (batch_y.size(1) - 1)\n","    total_loss += batch_loss.item()\n","    if n_batch % 100 == 0:\n","      print(f\"Iteration:{n_batch}, Loss: {[batch_loss.item()]}\")\n","\n","    batch_loss.backward()\n","    optimizer.step()\n","\n","  print(f\"Epoch:{epoch+1}, Loss: {[total_loss/n_batch]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3KfL9BONMw7"},"outputs":[],"source":["with torch.no_grad():\n","  preds = []\n","  true = []\n","  total_loss = 0\n","  n_batch = 0\n","  for batch_x, batch_y in test_loader:\n","        n_batch += 1\n","        batch_x = batch_x.cuda()\n","        batch_y = batch_y.cuda()\n","        true.extend(scaler.inverse_transform(batch_y.detach().cpu().numpy()))\n","        batch_x = batch_x.unsqueeze(2)\n","        batch_y = batch_y.unsqueeze(2)\n","        encoder_output, encoder_hidden = encoder(batch_x)\n","        dec_input = batch_y[:, 0].view(1, 1, 1)\n","        temp = dec_input.detach().cpu().numpy()\n","        preds.append(scaler.inverse_transform(temp.reshape(1, -1)))\n","\n","        dec_hidden = encoder_hidden\n","        for t in range(1, batch_y.size(1)):\n","          predictions, dec_hidden, _ = decoder(dec_input.to(device), dec_hidden.to(device), enc_output.to(device))\n","          best_guess = predictions.detach().cpu().numpy()\n","          preds.append(scaler.inverse_transform(best_guess.reshape(1, -1)))\n","          dec_input = predictions.view(batch_y.size(0), 1, 1)\n","\n","\n","\n","  preds = np.concatenate(preds)\n","  true = np.concatenate(true)\n","  mse = mean_squared_error(true, preds)\n","  mae = mean_absolute_error(true, preds)\n","\n","  print(mse, mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCGMaItWOWmb"},"outputs":[],"source":["preds.shape, true.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IqNg2OUOWst"},"outputs":[],"source":["preds_reshaped = preds[996:].reshape(-1, 500)\n","true_reshaped = true[996:].reshape(-1, 500)\n","\n","preds_avg = np.mean(preds_reshaped, axis=1)\n","true_avg = np.mean(true_reshaped, axis=1)\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(preds_avg, 'b', label='Preds')\n","plt.plot(true_avg, 'g', label='True')\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"dryice","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
